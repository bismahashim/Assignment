{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ1XUV3fWA3uYnyHLKw6xt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bismahashim/Assignment/blob/main/Text_Mining___review_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gD7M61IPjgUN"
      },
      "outputs": [],
      "source": [
        "import requests   # Importing requests to extract content from a url\n",
        "from bs4 import BeautifulSoup as bs # Beautifulsoup is for web scrapping...used to scrap specific content \n",
        "import re \n",
        "iphone_reviews=[]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Extracting reviews from Amazon website ################\n",
        "for i in range(1,10):\n",
        "  ip=[]  \n",
        "  url=\"https://www.amazon.in/Apple-MacBook-Air-13-3-inch-Integrated/product-reviews/B073Q5R6VR/ref=cm_cr_arp_d_paging_btm_2?showViewpoints=1&pageNumber=\"+str(i)\n",
        "  response = requests.get(url)\n",
        "  soup = bs(response.content,\"html.parser\")# creating soup object to iterate over the extracted content \n",
        "  reviews = soup.findAll(\"span\",attrs={\"class\",\"a-size-base review-text\"})# Extracting the content under specific tags  \n",
        "  for i in range(len(reviews)):\n",
        "    ip.append(reviews[i].text)  \n",
        "  iphone_reviews=iphone_reviews+ip  # adding the reviews of one page to empty list which in future contains all the reviews\n"
      ],
      "metadata": {
        "id": "UM4lXZVcjrtZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# writng reviews in a text file \n",
        "with open(\"iphone.txt\",\"w\",encoding='utf8') as output:\n",
        "    output.write(str(iphone_reviews))"
      ],
      "metadata": {
        "id": "veoAFCvyjtEF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "########### Extracting reviews from snapdeal website ##############\n",
        "\n",
        "iphone_snapdeal=[]\n",
        "url1 = \"https://www.snapdeal.com/product/apple-iphone-5c-16-gb/988871559/reviews?page=\"\n",
        "url2 = \"&sortBy=RECENCY&vsrc=rcnt#defRevPDP\"\n",
        "### Extracting reviews from Amazon website ################\n",
        "for i in range(1,10):\n",
        "  ip=[]  \n",
        "  base_url = url1+str(i)+url2\n",
        "  response = requests.get(base_url)\n",
        "  soup = bs(response.content,\"html.parser\")# creating soup object to iterate over the extracted content \n",
        "  temp = soup.findAll(\"div\",attrs={\"class\",\"user-review\"})# Extracting the content under specific tags  \n",
        "  for j in range(len(temp)):\n",
        "    ip.append(temp[j].find(\"p\").text)\n",
        "  iphone_snapdeal=iphone_snapdeal+ip  # adding the reviews of one page to empty list which in future contains all the reviews\n"
      ],
      "metadata": {
        "id": "z9UlVnx2juhn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Removing repeated reviews \n",
        "iphone_snapdeal = list(set(iphone_snapdeal))\n"
      ],
      "metadata": {
        "id": "nEmj-_xujv7z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing reviews into text file \n",
        "with open(\"ip_snapdeal.txt\",\"w\",encoding=\"utf-8\") as snp:\n",
        "    snp.write(str(iphone_snapdeal))"
      ],
      "metadata": {
        "id": "SENGPKR6jxB3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tpfPAcAxjyOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}